{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 참고자료: https://a292run.tistory.com/entry/Facial-Expression-Recognition-with-Keras-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/icml_face_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    \"\"\" Prepare data for modeling \n",
    "        input: data frame with labels und pixel data\n",
    "        output: image and label array \"\"\"\n",
    "    \n",
    "    image_array = np.zeros(shape=(len(data), 48, 48))\n",
    "    image_label = np.array(list(map(int, data['emotion'])))\n",
    "    \n",
    "    for i, row in enumerate(data.index):\n",
    "        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n",
    "        image = np.reshape(image, (48, 48))\n",
    "        image_array[i] = image\n",
    "        \n",
    "    return image_array, image_label\n",
    "  \n",
    "def plot_examples(label=0):\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(25, 12))\n",
    "    fig.subplots_adjust(hspace = .2, wspace=.2)\n",
    "    axs = axs.ravel()\n",
    "    for i in range(5):\n",
    "        idx = data[data['emotion']==label].index[i]\n",
    "        axs[i].imshow(train_images[idx][:,:,0], cmap='gray')\n",
    "        axs[i].set_title(emotions[train_labels[idx].argmax()])\n",
    "        axs[i].set_xticklabels([])\n",
    "        axs[i].set_yticklabels([])\n",
    "\n",
    "def plot_all_emotions():\n",
    "    fig, axs = plt.subplots(1, 7, figsize=(30, 12))\n",
    "    fig.subplots_adjust(hspace = .2, wspace=.2)\n",
    "    axs = axs.ravel()\n",
    "    for i in range(7):\n",
    "        idx = data[data['emotion']==i].index[i]\n",
    "        axs[i].imshow(train_images[idx][:,:,0], cmap='gray')\n",
    "        axs[i].set_title(emotions[train_labels[idx].argmax()])\n",
    "        axs[i].set_xticklabels([])\n",
    "        axs[i].set_yticklabels([])\n",
    "\n",
    "def plot_image_and_emotion(test_image_array, test_image_label, pred_test_labels, image_number):\n",
    "    \"\"\" Function to plot the image and compare the prediction results with the label \"\"\"\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=False)\n",
    "    \n",
    "    bar_label = emotions.values()\n",
    "    \n",
    "    axs[0].imshow(test_image_array[image_number], 'gray')\n",
    "    axs[0].set_title(emotions[test_image_label[image_number]])\n",
    "    \n",
    "    axs[1].bar(bar_label, pred_test_labels[image_number], color='orange', alpha=0.7)\n",
    "    axs[1].grid()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_compare_distributions(array1, array2, title1='', title2=''):\n",
    "    df_array1 = pd.DataFrame()\n",
    "    df_array2 = pd.DataFrame()\n",
    "    df_array1['emotion'] = array1.argmax(axis=1)\n",
    "    df_array2['emotion'] = array2.argmax(axis=1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=False)\n",
    "    x = emotions.values()\n",
    "    \n",
    "    y = df_array1['emotion'].value_counts()\n",
    "    keys_missed = list(set(emotions.keys()).difference(set(y.keys())))\n",
    "    for key_missed in keys_missed:\n",
    "        y[key_missed] = 0\n",
    "    axs[0].bar(x, y.sort_index(), color='orange')\n",
    "    axs[0].set_title(title1)\n",
    "    axs[0].grid()\n",
    "    \n",
    "    y = df_array2['emotion'].value_counts()\n",
    "    keys_missed = list(set(emotions.keys()).difference(set(y.keys())))\n",
    "    for key_missed in keys_missed:\n",
    "        y[key_missed] = 0\n",
    "    axs[1].bar(x, y.sort_index())\n",
    "    axs[1].set_title(title2)\n",
    "    axs[1].grid()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_array, train_image_label = prepare_data(data[data[' Usage']=='Training'])\n",
    "val_image_array, val_image_label = prepare_data(data[data[' Usage']=='PrivateTest'])\n",
    "test_image_array, test_image_label = prepare_data(data[data[' Usage']=='PublicTest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_image_array.reshape((train_image_array.shape[0], 48, 48, 1))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "val_images = val_image_array.reshape((val_image_array.shape[0], 48, 48, 1))\n",
    "val_images = val_images.astype('float32')/255\n",
    "\n",
    "test_images = test_image_array.reshape((test_image_array.shape[0], 48, 48, 1))\n",
    "test_images = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_image_label)\n",
    "val_labels = to_categorical(val_image_label)\n",
    "test_labels = to_categorical(test_image_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "#1st convolution layer\n",
    "model.add(tf.keras.layers.Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(keras.layers.Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 44, 44, 64)        1664      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 20, 20, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 18, 18, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 7, 7, 64)         0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 5, 5, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 3, 3, 128)         147584    \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 1, 1, 128)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              132096    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,485,831\n",
      "Trainable params: 1,485,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def callbackFunction(modelName):\n",
    "  checkpoint = ModelCheckpoint(f\"Checkpoints/{modelName}.h5\", monitor = \"val_accuracy\", save_best_only = True, mode = \"auto\", verbose = 1)\n",
    "  early_stopping = EarlyStopping(monitor = \"val_accuracy\", patience = 10, verbose = 1)\n",
    "  callbacks = [early_stopping, checkpoint]\n",
    "  return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy'\n",
    "            , optimizer=keras.optimizers.Adam()\n",
    "            , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/conv2d/Conv2D' defined at (most recent call last):\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 497, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 404, in dispatch_shell\n      await result\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 728, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\jongm\\AppData\\Local\\Temp\\ipykernel_10876\\2791800245.py\", line 1, in <cell line: 1>\n      history1 = model.fit(train_images, train_labels,\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 225, in convolution_op\n      return tf.nn.convolution(\nNode: 'sequential/conv2d/Conv2D'\nDNN library is not found.\n\t [[{{node sequential/conv2d/Conv2D}}]] [Op:__inference_train_function_1276]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jongm\\OneDrive - 광운대학교\\ProjecTS\\Facial-Expression-Recognition\\dataprocessing\\make_tfrecord.ipynb 셀 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jongm/OneDrive%20-%20%EA%B4%91%EC%9A%B4%EB%8C%80%ED%95%99%EA%B5%90/ProjecTS/Facial-Expression-Recognition/dataprocessing/make_tfrecord.ipynb#ch0000024?line=0'>1</a>\u001b[0m history1 \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_images, train_labels,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jongm/OneDrive%20-%20%EA%B4%91%EC%9A%B4%EB%8C%80%ED%95%99%EA%B5%90/ProjecTS/Facial-Expression-Recognition/dataprocessing/make_tfrecord.ipynb#ch0000024?line=1'>2</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(val_images, val_labels),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jongm/OneDrive%20-%20%EA%B4%91%EC%9A%B4%EB%8C%80%ED%95%99%EA%B5%90/ProjecTS/Facial-Expression-Recognition/dataprocessing/make_tfrecord.ipynb#ch0000024?line=2'>3</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49mcallbackFunction(\u001b[39m'\u001b[39;49m\u001b[39mCase_1\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jongm/OneDrive%20-%20%EA%B4%91%EC%9A%B4%EB%8C%80%ED%95%99%EA%B5%90/ProjecTS/Facial-Expression-Recognition/dataprocessing/make_tfrecord.ipynb#ch0000024?line=3'>4</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jongm/OneDrive%20-%20%EA%B4%91%EC%9A%B4%EB%8C%80%ED%95%99%EA%B5%90/ProjecTS/Facial-Expression-Recognition/dataprocessing/make_tfrecord.ipynb#ch0000024?line=4'>5</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/conv2d/Conv2D' defined at (most recent call last):\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 497, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 404, in dispatch_shell\n      await result\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 728, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\jongm\\AppData\\Local\\Temp\\ipykernel_10876\\2791800245.py\", line 1, in <cell line: 1>\n      history1 = model.fit(train_images, train_labels,\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"c:\\Users\\jongm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 225, in convolution_op\n      return tf.nn.convolution(\nNode: 'sequential/conv2d/Conv2D'\nDNN library is not found.\n\t [[{{node sequential/conv2d/Conv2D}}]] [Op:__inference_train_function_1276]"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(train_images, train_labels,\n",
    "                    validation_data=(val_images, val_labels),\n",
    "                    callbacks=callbackFunction('Case_1'),\n",
    "                    epochs=10,\n",
    "                    batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bc634c7defc278473aae0e09fa7640d960bf44daf98e7e8cc6d9b3487f2a802"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
